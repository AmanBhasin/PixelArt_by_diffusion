{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1b11297f-ca63-44e7-9aae-f161bf299eec",
    "_uuid": "5705d11d-e757-4920-86ba-15d20d7665a4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-24T11:43:21.599633Z",
     "iopub.status.busy": "2024-10-24T11:43:21.599351Z",
     "iopub.status.idle": "2024-10-24T11:43:21.606731Z",
     "shell.execute_reply": "2024-10-24T11:43:21.605922Z",
     "shell.execute_reply.started": "2024-10-24T11:43:21.599602Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network modules and utility functions for image processing and data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Unet import UNet  #U_Net class for building UNet Encoder-Decoder\n",
    "from custom_dataset import CustomDataset #Functions for Dataset Handling\n",
    "from utils import  plot_sample, unorm, norm_all # Utility functions for Animation Processing and Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_sample_with_intermidiate_steps(steps):\n",
    "    # Change to Numpy image format (h, w, channels) vs (channels, h, w) for a single sample\n",
    "    sx_gen_store = np.moveaxis(steps, 2, 4)\n",
    "    nsx_gen_store = norm_all(sx_gen_store, sx_gen_store.shape[0], 1)  # Unity normalization for np.imshow\n",
    "\n",
    "    # plot all 32 images in 8*4 grid\n",
    "    fig, axs = plt.subplots(nrows=8, ncols=4, sharex=True, sharey=True, figsize=(4, 8))\n",
    "    for i in range(8):\n",
    "        for j in range(4):\n",
    "            axs[i, j].imshow(nsx_gen_store[i*4+j, 0])\n",
    "            axs[i, j].set_xticks([])\n",
    "            axs[i, j].set_yticks([])\n",
    "\n",
    "    plt.show()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0c795920-1597-42f4-ab62-354711621c89",
    "_uuid": "ca01534e-af7e-42ef-aaae-65859959a1fc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-24T11:43:21.764469Z",
     "iopub.status.busy": "2024-10-24T11:43:21.763882Z",
     "iopub.status.idle": "2024-10-24T11:43:21.773635Z",
     "shell.execute_reply": "2024-10-24T11:43:21.772737Z",
     "shell.execute_reply.started": "2024-10-24T11:43:21.764422Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                \n",
    "    transforms.Normalize((0.5,), (0.5,))  # range [-1,1]\n",
    "    \n",
    "    # Augmentations for lesser sized dataset\n",
    "    # transforms.Lambda(quantize_image),\n",
    "    # transforms.RandomRotation(degrees=90),\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9d3a032b-91cd-4569-8ce4-ba65ff187027",
    "_uuid": "5770d69c-b5c8-489c-a516-1ed4153d5a82",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-24T11:43:21.775658Z",
     "iopub.status.busy": "2024-10-24T11:43:21.775378Z",
     "iopub.status.idle": "2024-10-24T11:43:21.782079Z",
     "shell.execute_reply": "2024-10-24T11:43:21.781313Z",
     "shell.execute_reply.started": "2024-10-24T11:43:21.775628Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# data hyperparameters\n",
    "num_sprites = 25000\n",
    "\n",
    "# diffusion hyperparameters\n",
    "timesteps = 500\n",
    "beta1 = 1e-4\n",
    "beta2 = 0.02\n",
    "\n",
    "# network hyperparameters\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else torch.device('cpu'))\n",
    "n_feat = 64 # 64 hidden dimension feature\n",
    "context_size = 5 # context vector is of size 5\n",
    "height = 16 # 16x16 image\n",
    "save_dir = './model/'\n",
    "\n",
    "# training hyperparameters\n",
    "batch_size = 100\n",
    "n_epoch = 150 \n",
    "lrate=1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Noise schedulings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "25aa91c5-8582-4f80-a2e7-1a4057839eea",
    "_uuid": "18323c40-14ed-4ddb-9b0b-2487fcbe3f04",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-24T11:43:21.783653Z",
     "iopub.status.busy": "2024-10-24T11:43:21.783315Z",
     "iopub.status.idle": "2024-10-24T11:43:21.792199Z",
     "shell.execute_reply": "2024-10-24T11:43:21.791361Z",
     "shell.execute_reply.started": "2024-10-24T11:43:21.783621Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# linear schedule \n",
    "# b_t = (beta2 - beta1) * torch.linspace(0, 1, timesteps + 1, device=device) + beta1\n",
    "# a_t = 1 - b_t\n",
    "# ab_t = torch.cumsum(a_t.log(), dim=0).exp()    \n",
    "# ab_t[0] = 1\n",
    "\n",
    "# cosine schedule\n",
    "def cosine_schedule(timesteps, s=0.008):\n",
    "    x = torch.linspace(0, timesteps, timesteps + 1, device=device)\n",
    "    return torch.cos((x / timesteps + s) / (1 + s) * torch.pi / 2) ** 2\n",
    "\n",
    "b_t = beta1 + (beta2 - beta1) * (1 - cosine_schedule(timesteps))\n",
    "a_t = 1 - b_t\n",
    "ab_t = torch.cumsum(a_t.log(), dim=0).exp()\n",
    "ab_t[0] = 1\n",
    "\n",
    "# quadratic schedule\n",
    "# b_t = beta1 + (beta2 - beta1) * (torch.linspace(0, 1, timesteps + 1, device=device) ** 2)\n",
    "# a_t = 1 - b_t\n",
    "# ab_t = torch.cumsum(a_t.log(), dim=0).exp()\n",
    "# ab_t[0] = 1\n",
    "\n",
    "# exponential schedule\n",
    "# b_t = beta1 * (beta2 / beta1) ** torch.linspace(0, 1, timesteps + 1, device=device)\n",
    "# a_t = 1 - b_t\n",
    "# ab_t = torch.cumsum(a_t.log(), dim=0).exp()\n",
    "# ab_t[0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1a1c3371-ab6c-41df-88dd-43ecf7ccd746",
    "_uuid": "9b9c1d57-e9fa-4000-b36a-0d5bc92318ec",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-24T11:43:21.794259Z",
     "iopub.status.busy": "2024-10-24T11:43:21.793452Z",
     "iopub.status.idle": "2024-10-24T11:43:21.827233Z",
     "shell.execute_reply": "2024-10-24T11:43:21.826549Z",
     "shell.execute_reply.started": "2024-10-24T11:43:21.794220Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "nn_model = UNet(in_channels=3, num_feature_maps=n_feat, context_size=context_size, image_size=height).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bf1d138f-7d0c-41af-9282-a81f919dd627",
    "_uuid": "7ec7bfd4-1b14-46e4-884b-8e329b47e732",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-24T11:43:21.837126Z",
     "iopub.status.busy": "2024-10-24T11:43:21.836813Z",
     "iopub.status.idle": "2024-10-24T11:43:21.875067Z",
     "shell.execute_reply": "2024-10-24T11:43:21.874010Z",
     "shell.execute_reply.started": "2024-10-24T11:43:21.837068Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset(\"./data_dir/sprites.npy\",\"./data_dir/sprites_labels.npy\", transform, nums_sprites=num_sprites, null_context=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "sample_idx = np.random.choice(len(dataset.sprites), 10)\n",
    "sample = [dataset.sprites[i] for i in sample_idx]\n",
    "fig, ax = plt.subplots(1, 10, figsize=(20, 2))\n",
    "for i in range(10):\n",
    "    ax[i].imshow(sample[i])\n",
    "    ax[i].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T11:43:21.877079Z",
     "iopub.status.busy": "2024-10-24T11:43:21.876417Z",
     "iopub.status.idle": "2024-10-24T11:43:21.883937Z",
     "shell.execute_reply": "2024-10-24T11:43:21.883062Z",
     "shell.execute_reply.started": "2024-10-24T11:43:21.877032Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "optim = torch.optim.Adam(nn_model.parameters(), lr=lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c42e9bb5-0e01-4837-b850-41904ec87fc6",
    "_uuid": "b146ef9b-f82a-401f-856a-a696877e2de0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-24T11:43:21.885410Z",
     "iopub.status.busy": "2024-10-24T11:43:21.885051Z",
     "iopub.status.idle": "2024-10-24T11:43:21.890895Z",
     "shell.execute_reply": "2024-10-24T11:43:21.889974Z",
     "shell.execute_reply.started": "2024-10-24T11:43:21.885369Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# helper function: perturbs an image to a specified noise level\n",
    "def perturb_input(x, t, noise):\n",
    "    return ab_t.sqrt()[t, None, None, None] * x + (1 - ab_t[t, None, None, None]) * noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "860027cd-e748-4a0a-b3f3-2bc68860418a",
    "_kg_hide-output": true,
    "_uuid": "bb1e120b-b3d6-4975-bdbc-15a94dc6ee2f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-24T11:43:21.892591Z",
     "iopub.status.busy": "2024-10-24T11:43:21.892227Z",
     "iopub.status.idle": "2024-10-24T11:48:07.337040Z",
     "shell.execute_reply": "2024-10-24T11:48:07.335957Z",
     "shell.execute_reply.started": "2024-10-24T11:43:21.892550Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# set into train mode\n",
    "nn_model.train()\n",
    "\n",
    "losses = []\n",
    "\n",
    "for ep in range(n_epoch):\n",
    "    print(f'epoch {ep}')\n",
    "    \n",
    "    # linearly decay learning rate\n",
    "    optim.param_groups[0]['lr'] = lrate*(1-ep/n_epoch)\n",
    "    \n",
    "    pbar = tqdm(dataloader, mininterval=2 )\n",
    "    for x, _ in pbar:   # x: images\n",
    "        optim.zero_grad()\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # perturb data\n",
    "        noise = torch.randn_like(x)\n",
    "        t = torch.randint(1, timesteps + 1, (x.shape[0],)).to(device) \n",
    "        x_pert = perturb_input(x, t, noise)\n",
    "        \n",
    "        # use network to recover noise\n",
    "        pred_noise = nn_model(x_pert, t / timesteps)\n",
    "        \n",
    "        # loss is mean squared error between the predicted and true noise\n",
    "        loss = F.mse_loss(pred_noise, noise)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "plt.plot(losses)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T11:48:07.339855Z",
     "iopub.status.busy": "2024-10-24T11:48:07.338888Z",
     "iopub.status.idle": "2024-10-24T11:48:07.370349Z",
     "shell.execute_reply": "2024-10-24T11:48:07.369446Z",
     "shell.execute_reply.started": "2024-10-24T11:48:07.339805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# save model periodically\n",
    "torch.save(nn_model.state_dict(), save_dir + f\"model_{n_epoch}_{num_sprites}.pth\")\n",
    "print('saved model at ' + save_dir + f\"model_{n_epoch}_{num_sprites}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5e6a7f69-18d3-4029-a4f9-f949e45ecffd",
    "_uuid": "457e2850-278b-4d5f-be8a-31e803e2d4bc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-24T11:48:07.372205Z",
     "iopub.status.busy": "2024-10-24T11:48:07.371565Z",
     "iopub.status.idle": "2024-10-24T11:48:07.377625Z",
     "shell.execute_reply": "2024-10-24T11:48:07.376720Z",
     "shell.execute_reply.started": "2024-10-24T11:48:07.372161Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# removes the predicted noise (but adds some noise back in to avoid collapse)\n",
    "def denoise_add_noise(x, t, pred_noise, z=None):\n",
    "    if z is None:\n",
    "        z = torch.randn_like(x)\n",
    "    noise = b_t.sqrt()[t] * z\n",
    "    mean = (x - pred_noise * ((1 - a_t[t]) / (1 - ab_t[t]).sqrt())) / a_t[t].sqrt()\n",
    "    return mean + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "aaf0ba9f-962f-4e69-b55c-99d771c2eba0",
    "_uuid": "660b4592-ab0c-40db-8144-b0fca7455042",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-24T11:48:07.379026Z",
     "iopub.status.busy": "2024-10-24T11:48:07.378716Z",
     "iopub.status.idle": "2024-10-24T11:48:07.387838Z",
     "shell.execute_reply": "2024-10-24T11:48:07.387023Z",
     "shell.execute_reply.started": "2024-10-24T11:48:07.378995Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# sample using standard algorithm\n",
    "@torch.no_grad()\n",
    "def sample_with_intermidiates_ddpm(n_sample, save_rate=20):\n",
    "    # x_T ~ N(0, 1), sample initial noise\n",
    "    samples = torch.randn(n_sample, 3, height, height).to(device)  \n",
    "\n",
    "    # store intermediate samples\n",
    "    intermediate = [] \n",
    "    for i in range(timesteps, 0, -1):\n",
    "        print(f'sampling timestep {i:3d}', end='\\r')\n",
    "        t = torch.tensor([i / timesteps])[:, None, None, None].to(device)\n",
    "        z = torch.randn_like(samples) if i > 1 else 0\n",
    "\n",
    "        eps = nn_model(samples, t)\n",
    "        samples = denoise_add_noise(samples, i, eps, z)\n",
    "        if i % save_rate ==0 or i==timesteps or i<8:\n",
    "            intermediate.append(samples.detach().cpu().numpy())\n",
    "\n",
    "    intermediate = np.stack(intermediate)\n",
    "    return samples, intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "71260547-fa36-443e-9fa5-fc447d7c8fea",
    "_uuid": "ad13d481-981b-4f3c-b983-64b5ed0cadd0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-24T11:48:07.390039Z",
     "iopub.status.busy": "2024-10-24T11:48:07.389308Z",
     "iopub.status.idle": "2024-10-24T11:48:07.431369Z",
     "shell.execute_reply": "2024-10-24T11:48:07.430500Z",
     "shell.execute_reply.started": "2024-10-24T11:48:07.389970Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# load in model weights and set to eval mode\n",
    "nn_model.load_state_dict(torch.load(f\"{save_dir}/model_{n_epoch}_{num_sprites}.pth\", map_location=device))\n",
    "nn_model.eval()\n",
    "print(\"Loaded in Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8e234400-d150-46be-8d40-f1edbc477de5",
    "_uuid": "1d4e281d-dfc4-41ff-a375-98d0da7d3bfc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-24T11:48:07.434301Z",
     "iopub.status.busy": "2024-10-24T11:48:07.434029Z",
     "iopub.status.idle": "2024-10-24T11:49:02.924278Z",
     "shell.execute_reply": "2024-10-24T11:49:02.923247Z",
     "shell.execute_reply.started": "2024-10-24T11:48:07.434272Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Sample one image and plot the intermediate steps\n",
    "n_sample = 1\n",
    "nrows = 5\n",
    "save_rate = 20\n",
    "sample, intermediate = sample_with_intermidiates_ddpm(n_sample, save_rate)\n",
    "samples_dir = 'samples/'\n",
    "\n",
    "plot_single_sample_with_intermidiate_steps(intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "samples, intermediate_ddpm = sample_with_intermidiates_ddpm(32)\n",
    "animation_ddpm = plot_sample(intermediate_ddpm,32,4,save_dir, \"ani_run\", None, save=False)\n",
    "HTML(animation_ddpm.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7f928b1e-5f60-4800-8756-d8f92ea45a52",
    "_uuid": "0c414f70-5df6-4899-80e0-9d56e6c9fe2f",
    "trusted": true
   },
   "source": [
    "# Acknowledgments\n",
    "Sprites by ElvGames, [FrootsnVeggies](https://zrghr.itch.io/froots-and-veggies-culinary-pixels) and  [kyrise](https://kyrise.itch.io/)   \n",
    "This code is modified from, https://github.com/cloneofsimo/minDiffusion   \n",
    "Diffusion model is based on [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239) and [Denoising Diffusion Implicit Models](https://arxiv.org/abs/2010.02502)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4424547,
     "sourceId": 7600561,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
